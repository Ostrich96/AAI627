{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uEIFaWNUCjOp",
        "outputId": "1cf84fd4-d9c2-4b03-942a-2c0103a1a3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.3.1-bin-hadoop3/\n",
            "spark-3.3.1-bin-hadoop3/LICENSE\n",
            "spark-3.3.1-bin-hadoop3/NOTICE\n",
            "spark-3.3.1-bin-hadoop3/R/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.3.1-bin-hadoop3/README.md\n",
            "spark-3.3.1-bin-hadoop3/RELEASE\n",
            "spark-3.3.1-bin-hadoop3/bin/\n",
            "spark-3.3.1-bin-hadoop3/bin/beeline\n",
            "spark-3.3.1-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.3.1-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.3.1-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.3.1-bin-hadoop3/bin/pyspark\n",
            "spark-3.3.1-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/run-example\n",
            "spark-3.3.1-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-class\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-shell\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-sql\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-submit\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/sparkR\n",
            "spark-3.3.1-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.3.1-bin-hadoop3/conf/\n",
            "spark-3.3.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.3.1-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.3.1-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.3.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.3.1-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.3.1-bin-hadoop3/conf/workers.template\n",
            "spark-3.3.1-bin-hadoop3/data/\n",
            "spark-3.3.1-bin-hadoop3/data/graphx/\n",
            "spark-3.3.1-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.3.1-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/als/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.3.1-bin-hadoop3/data/streaming/\n",
            "spark-3.3.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.3.1-bin-hadoop3/examples/\n",
            "spark-3.3.1-bin-hadoop3/examples/jars/\n",
            "spark-3.3.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.3.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/examples/src/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.3.1-bin-hadoop3/jars/\n",
            "spark-3.3.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/RoaringBitmap-0.9.25.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/antlr4-runtime-4.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arpack-2.2.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-format-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-memory-core-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-memory-netty-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-vector-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/automaton-1.11-8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/avro-1.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/avro-ipc-1.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/avro-mapred-1.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/blas-2.2.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/breeze-macros_2.12-1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/breeze_2.12-1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-compress-1.21.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-text-1.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/compress-lzf-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/core-1.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/generex-1.0.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-client-api-3.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-vector-code-gen-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/httpclient-4.5.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/httpcore-4.4.14.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/ivy-2.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-annotations-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-core-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-databind-2.13.4.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/janino-3.0.16.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jcl-over-slf4j-1.7.32.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/joda-time-2.10.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jul-to-slf4j-1.7.32.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-client-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apiextensions-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apps-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-autoscaling-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-batch-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-certificates-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-common-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-coordination-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-core-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-discovery-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-events-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-extensions-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-metrics-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-networking-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-node-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-policy-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-rbac-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-scheduling-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-storageclass-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/lapack-2.2.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-1.2-api-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-api-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-core-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-slf4j-impl-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-core-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-graphite-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-jmx-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-json-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-jvm-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-all-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-buffer-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-codec-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-common-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-handler-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-resolver-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-tcnative-classes-2.0.48.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/okio-1.14.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/orc-core-1.7.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/orc-mapreduce-1.7.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/orc-shims-1.7.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-column-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-common-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-encoding-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-format-structures-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-hadoop-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-jackson-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/pickle-1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/py4j-0.10.9.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/rocksdbjni-6.20.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-compiler-2.12.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-library-2.12.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-reflect-2.12.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/shapeless_2.12-2.3.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/shims-0.9.25.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/slf4j-api-1.7.32.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/snakeyaml-1.31.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/snappy-java-1.1.8.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-catalyst_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-core_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-graphx_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-hive_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-kvstore_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-launcher_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-mesos_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-mllib_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-network-common_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-repl_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-sketch_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-sql_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-streaming_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1-tests.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-unsafe_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-yarn_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/tink-1.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/velocity-1.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/xbean-asm9-shaded-4.20.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/xz-1.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zookeeper-3.6.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zookeeper-jute-3.6.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zstd-jni-1.5.2-1.jar\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile.java17\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.3.1-bin-hadoop3/licenses/\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-netlib.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scala.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.3.1-bin-hadoop3/python/\n",
            "spark-3.3.1-bin-hadoop3/python/.coveragerc\n",
            "spark-3.3.1-bin-hadoop3/python/.gitignore\n",
            "spark-3.3.1-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.3.1-bin-hadoop3/python/README.md\n",
            "spark-3.3.1-bin-hadoop3/python/dist/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.3.1-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.3.1-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.2_to_3.3.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/supported_pandas_api.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/lib/\n",
            "spark-3.3.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip\n",
            "spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.3.1-bin-hadoop3/python/mypy.ini\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/ml.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/streaming.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.3.1-bin-hadoop3/python/run-tests\n",
            "spark-3.3.1-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.3.1-bin-hadoop3/python/run-tests.py\n",
            "spark-3.3.1-bin-hadoop3/python/setup.cfg\n",
            "spark-3.3.1-bin-hadoop3/python/setup.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages.csv\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.3.1-bin-hadoop3/sbin/\n",
            "spark-3.3.1-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.3.1-bin-hadoop3/yarn/\n",
            "spark-3.3.1-bin-hadoop3/yarn/spark-3.3.1-yarn-shuffle.jar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ebf3b2f7-f85f-4ae7-bcbb-12f0da14b687\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ebf3b2f7-f85f-4ae7-bcbb-12f0da14b687\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ratings.csv to ratings.csv\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar -xvf spark-3.3.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "spark = SparkSession.builder.appName('recommend-ML').getOrCreate()\n",
        "df = spark.read.csv('ratings.csv', header = True, inferSchema = True)\n",
        "cols = df.columns\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct2BGk6zC0hn",
        "outputId": "216333f5-e5fc-43eb-df92-f18b6afb03b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- trackID: integer (nullable = true)\n",
            " |-- result: integer (nullable = true)\n",
            " |-- album_score: integer (nullable = true)\n",
            " |-- artist_score: integer (nullable = true)\n",
            " |-- genre1_score: integer (nullable = true)\n",
            " |-- genre2_score: integer (nullable = true)\n",
            " |-- genre3_score: integer (nullable = true)\n",
            " |-- genre4_score: integer (nullable = true)\n",
            " |-- genre5_score: integer (nullable = true)\n",
            " |-- genre6_score: integer (nullable = true)\n",
            " |-- genre7_score: integer (nullable = true)\n",
            " |-- genre8_score: integer (nullable = true)\n",
            " |-- genre9_score: integer (nullable = true)\n",
            " |-- genre10_score: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder,StringIndexer,VectorAssembler"
      ],
      "metadata": {
        "id": "yP7z9dr-DTEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numericCols = ['album_score', 'artist_score', 'genre1_score', 'genre2_score', 'genre3_score', 'genre4_score', 'genre5_score', 'genre6_score', 'genre7_score', 'genre8_score', 'genre9_score', 'genre10_score']\n",
        "stages = []\n",
        "assemblerInputs =  numericCols\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]"
      ],
      "metadata": {
        "id": "Cyklw43TDa6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_stringIdx = StringIndexer(inputCol = 'result', outputCol = 'label')# string to index, which translate YES and NO to 1 and 0\n",
        "stages += [label_stringIdx]"
      ],
      "metadata": {
        "id": "y1HCvVsZDpdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages = stages)\n",
        "pipelineModel = pipeline.fit(df)\n",
        "df = pipelineModel.transform(df)\n",
        "selectedCols = ['label', 'features'] + cols\n",
        "df = df.select(selectedCols)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3znT2rL-EJ_G",
        "outputId": "a40e3899-0b69-4a19-e779-b1a3e7e0fac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: double (nullable = false)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- trackID: integer (nullable = true)\n",
            " |-- result: integer (nullable = true)\n",
            " |-- album_score: integer (nullable = true)\n",
            " |-- artist_score: integer (nullable = true)\n",
            " |-- genre1_score: integer (nullable = true)\n",
            " |-- genre2_score: integer (nullable = true)\n",
            " |-- genre3_score: integer (nullable = true)\n",
            " |-- genre4_score: integer (nullable = true)\n",
            " |-- genre5_score: integer (nullable = true)\n",
            " |-- genre6_score: integer (nullable = true)\n",
            " |-- genre7_score: integer (nullable = true)\n",
            " |-- genre8_score: integer (nullable = true)\n",
            " |-- genre9_score: integer (nullable = true)\n",
            " |-- genre10_score: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(df.take(6), columns=df.columns).transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "sCDgcRiWEawS",
        "outputId": "c9f5dc39-aaa5-426e-a8fe-81c7efb303f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                               0  \\\n",
              "label                                                        0.0   \n",
              "features       [90.0, 50.0, 90.0, 80.0, -1.0, -1.0, -1.0, -1....   \n",
              "userID                                                    200031   \n",
              "trackID                                                    30877   \n",
              "result                                                         1   \n",
              "album_score                                                   90   \n",
              "artist_score                                                  50   \n",
              "genre1_score                                                  90   \n",
              "genre2_score                                                  80   \n",
              "genre3_score                                                  -1   \n",
              "genre4_score                                                  -1   \n",
              "genre5_score                                                  -1   \n",
              "genre6_score                                                  -1   \n",
              "genre7_score                                                  -1   \n",
              "genre8_score                                                  -1   \n",
              "genre9_score                                                  -1   \n",
              "genre10_score                                                 -1   \n",
              "\n",
              "                                                               1  \\\n",
              "label                                                        0.0   \n",
              "features       [90.0, -1.0, 90.0, 80.0, -1.0, -1.0, -1.0, -1....   \n",
              "userID                                                    200031   \n",
              "trackID                                                     8244   \n",
              "result                                                         1   \n",
              "album_score                                                   90   \n",
              "artist_score                                                  -1   \n",
              "genre1_score                                                  90   \n",
              "genre2_score                                                  80   \n",
              "genre3_score                                                  -1   \n",
              "genre4_score                                                  -1   \n",
              "genre5_score                                                  -1   \n",
              "genre6_score                                                  -1   \n",
              "genre7_score                                                  -1   \n",
              "genre8_score                                                  -1   \n",
              "genre9_score                                                  -1   \n",
              "genre10_score                                                 -1   \n",
              "\n",
              "                                                               2  \\\n",
              "label                                                        1.0   \n",
              "features       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....   \n",
              "userID                                                    200031   \n",
              "trackID                                                   130183   \n",
              "result                                                         0   \n",
              "album_score                                                   -1   \n",
              "artist_score                                                  -1   \n",
              "genre1_score                                                  -1   \n",
              "genre2_score                                                  -1   \n",
              "genre3_score                                                  -1   \n",
              "genre4_score                                                  -1   \n",
              "genre5_score                                                  -1   \n",
              "genre6_score                                                  -1   \n",
              "genre7_score                                                  -1   \n",
              "genre8_score                                                  -1   \n",
              "genre9_score                                                  -1   \n",
              "genre10_score                                                 -1   \n",
              "\n",
              "                                                               3  \\\n",
              "label                                                        1.0   \n",
              "features       [-1.0, -1.0, 90.0, -1.0, -1.0, -1.0, -1.0, -1....   \n",
              "userID                                                    200031   \n",
              "trackID                                                   198762   \n",
              "result                                                         0   \n",
              "album_score                                                   -1   \n",
              "artist_score                                                  -1   \n",
              "genre1_score                                                  90   \n",
              "genre2_score                                                  -1   \n",
              "genre3_score                                                  -1   \n",
              "genre4_score                                                  -1   \n",
              "genre5_score                                                  -1   \n",
              "genre6_score                                                  -1   \n",
              "genre7_score                                                  -1   \n",
              "genre8_score                                                  -1   \n",
              "genre9_score                                                  -1   \n",
              "genre10_score                                                 -1   \n",
              "\n",
              "                                                               4  \\\n",
              "label                                                        0.0   \n",
              "features       [90.0, 50.0, 90.0, 80.0, -1.0, -1.0, -1.0, -1....   \n",
              "userID                                                    200031   \n",
              "trackID                                                    34503   \n",
              "result                                                         1   \n",
              "album_score                                                   90   \n",
              "artist_score                                                  50   \n",
              "genre1_score                                                  90   \n",
              "genre2_score                                                  80   \n",
              "genre3_score                                                  -1   \n",
              "genre4_score                                                  -1   \n",
              "genre5_score                                                  -1   \n",
              "genre6_score                                                  -1   \n",
              "genre7_score                                                  -1   \n",
              "genre8_score                                                  -1   \n",
              "genre9_score                                                  -1   \n",
              "genre10_score                                                 -1   \n",
              "\n",
              "                                                               5  \n",
              "label                                                        1.0  \n",
              "features       [-1.0, 90.0, 90.0, 50.0, -1.0, -1.0, -1.0, -1....  \n",
              "userID                                                    200031  \n",
              "trackID                                                   227283  \n",
              "result                                                         0  \n",
              "album_score                                                   -1  \n",
              "artist_score                                                  90  \n",
              "genre1_score                                                  90  \n",
              "genre2_score                                                  50  \n",
              "genre3_score                                                  -1  \n",
              "genre4_score                                                  -1  \n",
              "genre5_score                                                  -1  \n",
              "genre6_score                                                  -1  \n",
              "genre7_score                                                  -1  \n",
              "genre8_score                                                  -1  \n",
              "genre9_score                                                  -1  \n",
              "genre10_score                                                 -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-200e43f1-37e7-40a5-83fb-5e501c37ecdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>features</th>\n",
              "      <td>[90.0, 50.0, 90.0, 80.0, -1.0, -1.0, -1.0, -1....</td>\n",
              "      <td>[90.0, -1.0, 90.0, 80.0, -1.0, -1.0, -1.0, -1....</td>\n",
              "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
              "      <td>[-1.0, -1.0, 90.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
              "      <td>[90.0, 50.0, 90.0, 80.0, -1.0, -1.0, -1.0, -1....</td>\n",
              "      <td>[-1.0, 90.0, 90.0, 50.0, -1.0, -1.0, -1.0, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userID</th>\n",
              "      <td>200031</td>\n",
              "      <td>200031</td>\n",
              "      <td>200031</td>\n",
              "      <td>200031</td>\n",
              "      <td>200031</td>\n",
              "      <td>200031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trackID</th>\n",
              "      <td>30877</td>\n",
              "      <td>8244</td>\n",
              "      <td>130183</td>\n",
              "      <td>198762</td>\n",
              "      <td>34503</td>\n",
              "      <td>227283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>result</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>album_score</th>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>90</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>artist_score</th>\n",
              "      <td>50</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>50</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre1_score</th>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>-1</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre2_score</th>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>80</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre3_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre4_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre5_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre6_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre7_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre8_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre9_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre10_score</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-200e43f1-37e7-40a5-83fb-5e501c37ecdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-200e43f1-37e7-40a5-83fb-5e501c37ecdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-200e43f1-37e7-40a5-83fb-5e501c37ecdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "train = df#.where(col(\"userID\").between(200596, 201720))\n",
        "#test = df.where(col(\"userID\").between(200031, 200563))\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "#print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OALRkSWLEjeg",
        "outputId": "4cbeb0d8-67b4-41b9-a8bf-57786b9f873c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 5739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=5000)\n",
        "lrModel = lr.fit(train)"
      ],
      "metadata": {
        "id": "UbCUZ0SkNDS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "beta = np.sort(lrModel.coefficients)\n",
        "plt.plot(beta)\n",
        "plt.ylabel('Beta Coefficients')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nz74_cGYNl_i",
        "outputId": "7802218f-7073-47c4-fd01-8d6a0066c240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingSummary = lrModel.summary\n",
        "roc = trainingSummary.roc.toPandas()\n",
        "plt.plot(roc['FPR'],roc['TPR'])\n",
        "plt.ylabel('False Positive Rate')\n",
        "plt.xlabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "wuv7FmizNo2n",
        "outputId": "e934810a-eb29-4f93-ebe6-39f7f3dcdc3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dc7CQHCKhAQWQQRVFxwQavVWre2al26WJeO02VsnZmObad22tHuY2cendaZdtqOM63ttHbVatux9DdaWwGXal2wrkBQEGQRSdgCBEhI8vn9cU7gEkm4QG5u7j3v5+NxHznL9577OYGcz/2e7/d8v4oIzMwsuyqKHYCZmRWXE4GZWcY5EZiZZZwTgZlZxjkRmJllnBOBmVnGORGYmWWcE4GVFUnLJG2TtEXSa5JukzS4U5k3SpojabOkRkm/lTS9U5mhkv5D0vL0WEvS9VFdfK4kfUzSC5KaJK2UdJekYwt5vmY9wYnAytHFETEYOB44AbixY4ek04DfA78BDgEmA88Cj0g6LC1TDcwGjgbOB4YCpwHrgFO6+MxvAh8HPgaMAKYBdwNv39fgJVXt63vMDoT8ZLGVE0nLgA9FxP3p+teAoyPi7en6w8DzEfGRTu+7F2iIiPdJ+hDwL8CUiNiSx2dOBeqA0yLiiS7KPAD8NCK+n65/II3zjHQ9gOuAvweqgN8BTRHxDznH+A3wYER8XdIhwLeBM4EtwDci4lt5/IrMXsc1AitbksYDFwCL0/Ua4I3AXXsofifwlnT5POB3+SSB1LnAyq6SwD54B/AGYDpwO3CFJAFIOgh4K3CHpArgtyQ1mXHp5/+9pLcd4OdbRjkRWDm6W9JmYAVQD3wx3T6C5P/86j28ZzXQcf9/ZBdlurKv5bvylYhYHxHbgIeBAN6U7rsM+FNEvAqcDNRGxE0R0RIRLwPfA67sgRgsg5wIrBy9IyKGAGcBR7LrAr8BaAfG7uE9Y4G16fK6Lsp0ZV/Ld2VFx0Ik92zvAK5KN70X+Fm6fChwiKSNHS/gM8CYHojBMsiJwMpWRDwI3Ab8W7reBPwJeM8eil9O0kAMcD/wNkmD8vyo2cB4STO7KdME1OSsH7ynkDut3w5cJulQkltGv0q3rwCWRsTwnNeQiLgwz3jNduNEYOXuP4C3SJqRrt8AvD/t6jlE0kGS/pmkV9A/pWV+QnKx/ZWkIyVVSBop6TOSXnexjYiXgP8Cbpd0lqRqSQMkXSnphrTYM8C7JNVIOhy4Zm+BR8TTJLWU7wP3RcTGdNcTwGZJ/yhpoKRKScdIOnl/fkFmTgRW1iKiAfgx8IV0/Y/A24B3kdzXf4Wki+kZ6QWdiGgmaTCuA/4AbCK5+I4CHu/ioz4G/CdwC7ARWAK8k6RRF+AbQAuwBvgRu27z7M3P01h+nnNObcBFJN1jl7IrWQzL85hmu3H3UTOzjHONwMws45wIzMwyzonAzCzjnAjMzDKu5Aa3GjVqVEyaNKnYYZiZlZSnnnpqbUTU7mlfySWCSZMmMW/evGKHYWZWUiS90tU+3xoyM8s4JwIzs4xzIjAzyzgnAjOzjHMiMDPLuIIlAkk/kFQv6YUu9kvStyQtlvScpBMLFYuZmXWtkDWC20gm/u7KBcDU9HUt8N8FjMXMzLpQsOcIIuIhSZO6KXIp8ON0JqbHJA2XNDYiemLKPzPbBxFBeyQ/A2iPoGNg4oh0PaccAUF02rfr/Z3fk+zr+j3tAW3tQXsEbe1BWwTt7bnL7LZt53HZFWO6tCvunO3xuu27Rl3eY5k0nk3bd3T6Pe0qu/t69/tzf8/78r5dp5UsnXvUGGZMGE5PK+YDZePImZoPWJlue10ikHQtSa2BiRMn9kpwlj0RwfqmFtY1tbB2SzP1m5pZtXEbLa3ttLa389KaLQyv6ZdeMHMveulFlJyLHsnFK0guXNt3tNPS1r6zbHvOhbc9gg1NO1jf1MLgAVWoIx46/v5ffxHb7SLXcUHMiSH3/R0XuN3jy7moW0mQYPTQAWWXCPIWEbcCtwLMnDnT/3XtgEQEazY18/BLDSxu2MIra7eybF0Ty9dvZWtL2x7fU1mRXJ7b2oNDhg1AElLyx1khIdi1jXSbQIjKCjGgXwX9KiuoqqzYua9CoiL9efDQgTRua2HM0AEM7l+FOrIBu47ZsU27bdtZcOfndezbuW0P8eXGTRpHx3srtOu4u59fsgy7jtlRdvfP2f09O2PqeE/FHrZJVFZ0/BQVFaKyYzn9udv+Tufd8XvZdc67/66SZV73e921Xa8rI8Swgf1Qxa5ydCrb1efn6mr/Xo/X+UAFVMxEsAqYkLM+Pt1mdsBa29pZ3bid5eu38sq6razYsJXVG7exdN1Wlq1tonFbUuWvqhCHjqxh0shBnDZlJBMOqqF2SH9GDq5m9JD+jBteQ/+qCioqeu+P0qy3FTMRzAKuk3QHycTcjW4fsHy1trWzpbmVNZuaWbauiWVrk2/0Ha9VG7bRmnPfo1+lGD1kAJNG1XDxjLFMGjmIY8cNY+akETu/7ZtlVcESgaTbgbOAUZJWAl8E+gFExHeAe4ALgcXAVuCDhYrFSktbe9DS2k795u2sb2rZed9+Q1MLKzZs5Z7nX2N9U8vr3ndQTT8mjqjh2HHDuOi4sUwcUcOEETUcOnIQBw8d4Au+WRcK2Wvoqr3sD+DvCvX5VjrWbmnmwUUNPL+qkV/9eSWbt7d2WbZfZXIxHzGomveeMpFB/as4ZfJBTB0zhKED+vVWyGZlpSQai608NLe28cq6rSyp38KShi0saWji/oVrdl74B/ar5JhxQxncv4o3HDaSrc2tHD9xOCMG9WdETTUjBlczqLqyVxvRzLLAicB63MatLcmFvr4pveAnF/3l67fSlnPf/pBhAzh+wnCaW9v52DlTOW3KSN++MSsCJwLbL+3twaqN21jcsCX9ht+085v+upz799VVFRw2ahDTxw7l4uPGMmX0YKbUDmbyqEEM6u//fmZ9gf8SrVsRwcoN21i4ehMLV2/m1Y3b2LC1hade2bDbBX/EoGqm1A7iLdPHMKV2MFNGD2JK7WDGH1Tjb/lmfZwTgb1O/abtzHr2VR5dso45dfU7t0tQO7g/QwZU8eZptcycNIKpY5Jv+CMGVRcxYjM7EE4ERmtbOwtWb+K7D77M0rVNLFi9aee+844aw8QRNVw0YyxHjBni2zlmZch/1RkVETy+dD2/e+E1bnt02c7th40axKfPP4KzjxjNkQcPcQ8dswxwIsigRxav5X0/eIK29qC6qoJTDxvBMYcM46IZh3B8AQa0MrO+zYkgQ9Zuaea/5i7hB48sBeCyk8bzT5cc7ds9ZhnnK0BGfORnTzGnrp6W1nYunzmej54zlQkjaoodlpn1AU4EZW77jjbe/4MneHzpegDuv/7NHD56cJGjMrO+xImgzN326DIeX7qeI8YM4c6/OY1hAz0ej5ntzomgjK3d0swtcxZz3lGj+f77Ty52OGbWRxVy8norsv+4/0W27WjjxguPKnYoZtaHORGUqUcXr+X2J1Zw9amHMqXWbQJm1jXfGiozbe3B5+5+gTvnrWDyqEFc/9ZpxQ7JzPo4J4Iyc+Ovn+POeSsB+OEHTvZkLWa2V04EZaS9PVi4ejMAC256GzXV/uc1s71zG0EZue3RZTy/qpEvX3q0k4CZ5c2JoEzMf7WRf723jvOOGs3Vpx5a7HDMrIQ4EZSBbS1tfOz2pxle04+vXTbDI4aa2T7x/YMSFxF8adZ8ljQ08dNr3uAJYsxsnzkRlLDWtnY+evvT3PvCa1xwzMGcMXVUsUMysxLkW0Ml7Iuz5nPvC6/xnpPG8++Xzyh2OGZWolwjKFHPr2zk508s56pTJvAv7ziWCk8Qb2b7yTWCEhQRfOm38xk5qJobLzzKScDMDogTQQn6zTOv8tQrG/j02470k8NmdsCcCEpMU3MrX7l3IceNH8ZlJ40vdjhmVgacCErMLXMXs2ZTM1+8+GjfEjKzHuFEUEJeWdfE9x9eyrtOGMdJhx5U7HDMrEw4EZSQL/+/hfSrFP94wZHFDsXMykhBE4Gk8yUtkrRY0g172D9R0lxJT0t6TtKFhYynlD34YgP3L1zDdedMZczQAcUOx8zKSMESgaRK4BbgAmA6cJWk6Z2KfQ64MyJOAK4E/qtQ8ZSyHW3t3PTb+UwaWcNfnTGp2OGYWZkpZI3gFGBxRLwcES3AHcClncoEMDRdHga8WsB4StaPHl3GkoYmPn/RdPpXVRY7HDMrM4VMBOOAFTnrK9Ntub4EXC1pJXAP8NE9HUjStZLmSZrX0NBQiFj7rIbNzXzz/pc464hazjlydLHDMbMyVOzG4quA2yJiPHAh8BNJr4spIm6NiJkRMbO2trbXgyymf7tvEdt2tPH5i6Z7eGkzK4hCJoJVwISc9fHptlzXAHcCRMSfgAGAh9BMPbdyI3c+tYK/OmMyU2oHFzscMytThUwETwJTJU2WVE3SGDyrU5nlwLkAko4iSQTZuvfThfb2ZJ6BkYP689FzDi92OGZWxgqWCCKiFbgOuA9YSNI7aL6kmyRdkhb7JPBhSc8CtwMfiIgoVEyl5H+fXsWfl2/k0+cfwRCPJ2RmBVTQYagj4h6SRuDcbV/IWV4AnF7IGErRivVb+eRdz3L0IUO57ESPJ2RmhVXsxmLrpLWtnQ/e9iQA73/jJI8nZGYF54lp+pgnl21gcf0Wvnnl8Vx6fOfetmZmPc81gj5m7qJ6qqsqeMv0McUOxcwywomgj3l6+QaOPHgINdWurJlZ73Ai6EPqN23nyWUbOHGih5g2s97jRNBHtLa1c93tT9OvUrzzBLcNmFnv8f2HPuL3C9bwxNL1/Nt7ZjBjwvBih2NmGeIaQR+xrqkFgDOneYQNM+tdeSUCSQMlHVHoYLJswaubABjQz8NMm1nv2msikHQx8Azwu3T9eEmdxwyyA9C4bQe3P7GcygpR40RgZr0snxrBl0gmmdkIEBHPAJMLGFPmPLCoHoBb3nsCVZW+W2dmvSufq86OiGjstM0Dw/WgHz6yjFGD+/PW6QcXOxQzy6B8EsF8Se8FKiVNlfRt4NECx5UZD73YwDMrNnLmtFEeV8jMiiKfRPBR4GigGfg50Ah8vJBBZcmPHl1G7ZD+/Ms7ji12KGaWUfkkgrdHxGcj4uT09Tngkr2+y/aqYXMzD7zYwLtPHM/AajcSm1lx5JMIbsxzm+2j3zyzirb24LKT/CSxmRVPl08WS7qAZEL5cZK+lbNrKNBa6MDKXUTwy6dWMmPCcA4fPaTY4ZhZhnVXI3gVmAdsB57Kec0C3lb40Mrb/Fc3UffaZi470bUBMyuuLmsEEfEs8Kykn0fEjl6MKRN+9eeVVFdWcPGMQ4odipllXD6Dzk2S9BVgOjCgY2NEHFawqDLgvhde4+wjaxleU13sUMws4/JpLP4h8N8k7QJnAz8GflrIoMrdyw1beLVxO2OHDSx2KGZmeSWCgRExG1BEvBIRXwLeXtiwytf2HW1c/t3HADjew02bWR+Qz62hZkkVwEuSrgNWAYMLG1b5Wt24nbVbmrl85nje4QlozKwPyKdG8HGgBvgYcBLwl8D7ChlUOXswHWDur988pciRmJkl9lojiIgn08UtwAclVQJXAo8XMrBydd/8NRw+ejBTal2pMrO+ocsagaShkm6U9J+S3qrEdcBi4PLeC7G8LFvX5LYBM+tTuqsR/ATYAPwJ+BDwGUDAO9M5CWw/NG7bwbCB/YodhpnZTt0lgsMi4lgASd8HVgMTI2J7r0RWhlpa29na0sZwJwIz60O6ayze+TRxRLQBK50EDkzjtuRXOqzGicDM+o7uagQzJG1KlwUMTNcFREQMLXh0ZWZnInCNwMz6kC5rBBFRGRFD09eQiKjKWc4rCUg6X9IiSYsl3dBFmcslLZA0X9LP9/dESkFHIhjqRGBmfUg+D5Ttl7Sb6S3AW4CVwJOSZkXEgpwyU0nmNjg9IjZIGl2oePqCxm0tAG4jMLM+JZ8HyvbXKcDiiHg5IlqAO4BLO5X5MHBLRGwAiIj6AsZTdL41ZGZ9USETwThgRc76ynRbrmnANEmPSHpM0vl7OpCkayXNkzSvoaGhQOEWXuNWJwIz63vySgSSDpV0Xro8UFJPTalVBUwFzgKuAr4n6XVPW0XErRExMyJm1tbW9tBH9751TS1UyInAzPqWvSYCSR8Gfgl8N900Hrg7j2OvAibkrI9Pt+VaCcyKiB0RsRR4kSQxlKVVG7YxdthAqioLWREzM9s3+VyR/g44HdgEEBEvAfk06j4JTJU0WVI1yfhEszqVuZukNoCkUSS3il7OK/IStHz9VsYN9xwEZta35JMImtPGXgAkVQGxtzdFRCtwHXAfsBC4MyLmS7pJ0iVpsfuAdZIWAHOBT0XEun09iVKwpbmV51Y2MmPCsGKHYma2m3y6jz4o6TMkD5S9BfgI8Nt8Dh4R9wD3dNr2hZzlAK5PX2Xtjy+tpaWtnXOOHFPsUMzMdpNPjeAGoAF4Hvhrkgv75woZVDmaW1fPkAFVzJx0ULFDMTPbTT41gncAP46I7xU6mHLV3h7MWVTPmdNq6eeGYjPrY/K5Kl0MvCjpJ5IuStsIbB+88GojDZubOeeIsn5w2sxK1F4TQUR8EDgcuIukr/+SdFhqy9OcunokOOuI0n0GwszKV17f7iNih6R7SXoLDSS5XfShQgZWTubU1XPChOGMHNy/2KGYmb1OPg+UXSDpNuAl4N3A94GDCxxX2ajfvJ3nVjZyzpG+LWRmfVM+NYL3Ab8A/joimgscT9l5oC4ZG8ndRs2sr9prIoiIq3ojkHI1u24NY4cN4KixPTU8k5lZz+ry1pCkP6Y/N0valPPanDNzmXWjubWNP760lrOPHI2kYodjZrZHXdYIIuKM9Ke/yu6nJ5aup6mlzd1GzaxPy6ex+Cf5bLPXm1NXT/+qCk4/fFSxQzEz61I+D5QdnbuSPlB2UmHCKR8RwZy6et44ZSQDqyuLHY6ZWZe6ayO4UdJm4Ljc9gFgDfCbXouwRL28tolX1m11t1Ez6/O6TAQR8ZW0feDmiBiavoZExMiIuLEXYyxJcxYm0y+f7URgZn1cl43Fko6MiDrgLkkndt4fEX8uaGQlbnbdGo4YM4TxB9UUOxQzs2519xzB9cC1wL/vYV8A5xQkojLQuG0H85Zt4MNnHlbsUMzM9qq77qPXpj/P7r1wysPDLzXQ2h6c69tCZlYC8uk++h5JQ9Llz0n6taQTCh9a6ZpTV8/wmn6cMNGT0JhZ35dP99HPR8RmSWcA5wH/A3ynsGGVrrb24IFFDZw1rZbKCj9NbGZ9Xz6JoC39+Xbg1oj4P6C6cCGVtmdWbGR9U4t7C5lZycgnEayS9F3gCuAeSf3zfF8mza2rp7JCvHmaJ6Exs9KQzwX9cuA+4G0RsREYAXyqoFGVsNl19Zw08SCG17jSZGalIZ+pKrcCS4C3SboOGB0Rvy94ZCVodeM2Fq7exDlH+baQmZWOfHoNfRz4GTA6ff1U0kcLHVgpmlOXPE3sbqNmVkrymaHsGuANEdEEIOmrwJ+AbxcysFI0t66e8QcN5PDRg4sdiplZ3vJpIxC7eg6RLrtfZCfbd7Txx8VrOdeT0JhZicmnRvBD4HFJ/5uuv4PkWQLL8acl69i+o93dRs2s5OQzZ/HXJT0AnJFu+mBEPF3QqErQnLp6Bvar5NTDRhY7FDOzfdLd6KNvAG4FpgDPA9dExILeCqyUdExCc8bUUQzo50lozKy0dNdGcAvwD8BI4OvAN3olohL04potrNq4zZPQmFlJ6i4RVETEHyKiOSLuAvyobBdm160B4GxPUm9mJai7RDBc0rs6XntY3ytJ50taJGmxpBu6KfduSSFp5r6eQF8wZ2E9Rx8ylIOHDSh2KGZm+6y7xuIHgYu7WA/g190dWFIlye2ltwArgSclzerczpAOcf1x4PF9C71v2NDUwp+Xb+C6sw8vdihmZvulu4lpPniAxz4FWBwRLwNIugO4FOjc4Pxl4KuU6PhFD77YQHvAOUeNKXYoZmb7pZCjiI4DVuSsr0y37ZTOhTwhHdq6S5KulTRP0ryGhoaej/QAzKmrZ9Tgao4bN6zYoZiZ7ZeiDSctqYKkN9In91Y2Im6NiJkRMbO2tu+0Wbe2tfPAonrOOmI0FZ6ExsxKVCETwSpgQs76+HRbhyHAMcADkpYBpwKzSqnB+M/LN7Jpe6u7jZpZSctn9NEaSZ+X9L10faqki/I49pPAVEmTJVUDVwKzOnZGRGNEjIqISRExCXgMuCQi5u3XmRTB7Lo1VFWIN00dVexQzMz2Wz41gh8CzcBp6foq4J/39qaIaAWuI5nUZiFwZ0TMl3STpEv2M94+Zc7Cek6ZPIIhA/oVOxQzs/2Wz6BzUyLiCklXQTJRjfIcXjMi7gHu6bTtC12UPSufY/YVK9Zv5aX6LVxx8oS9FzYz68PyqRG0SBpI8uwAkqaQ1BAybeckNO42amYlLp8awReB3wETJP0MOB34QCGDKgVz6uqZPGoQk0cNKnYoZmYHJJ9hqP8g6c8kvXoEfDwi1hY8sj6sqbmVPy1Zx1+edmixQzEzO2D59Bo6HdiePvQ1HPiMpExfAR9ZvJaWtnZ3GzWzspBPG8F/A1slzQCuB5YAPy5oVH3c3EX1DO5fxcmTRhQ7FDOzA5ZPImiNiCAZJ+iWiLiF5GGwTOqYhObMaaOorirag9lmZj0mn8bizZJuBK4GzkyHhshsx/n5r25izaZmzz1gZmUjn6+0V5B0F70mIl4jGSri5oJG1YfNqatHgrOcCMysTOTTa+g1ksHhOtaXk+E2gjl19Rw3fji1Q/oXOxQzsx7R3eT1m0kfIuu8C4iIGFqwqPqohs3NPLtyI584b1qxQzEz6zHdTUyT2QbhrjywqJ4I3G3UzMpKPo3FAEgaDeyclDe9RZQpcxfVM2Zof44+JHOVITMrY/k8UHaJpJeApSTzFi8D7i1wXH1OS2s7D724lnOOHE2eY+6ZmZWEfHoNfZlkeIkXI2IycC7J3AGZMm/ZerY0t7rbqJmVnXwSwY6IWAdUSKqIiLlAycwi1lNm19VTXVXB6Yd7EhozKy/5tBFslDQYeAj4maR6oKmwYfU9c+rqOfWwkQzqn3eziplZSeiyRiBpYrp4KbAV+ATJcNRLgIsLH1rf8XLDFpaubeJc9xYyszLU3dfbu4ETI6JJ0q8i4t3Aj3oprj6lYxIadxs1s3LUXRtBbteYwwodSF82d1E9U0cPZsKImmKHYmbW47pLBNHFcqZs3r6Dx19ezzlHuTZgZuWpu1tDMyRtIqkZDEyXIWNDTDz80lpa24Nz3G3UzMpUd0NMVPZmIH3VnLp6hg6o4qRDDyp2KGZmBeGZVbrR3h48sKieNx8xmqpK/6rMrDz56taN51Y1snZLi7uNmllZcyLoxpyFa6gQvHlabbFDMTMrGCeCbsxZVM+JEw/ioEHVxQ7FzKxgnAi68Frjdl5YtcndRs2s7DkRdGHuIj9NbGbZ4ETQhTl19YwbPpAjxniiNjMrb04Ee7B9Rxt/fMmT0JhZNhQ0EUg6X9IiSYsl3bCH/ddLWiDpOUmzJR1ayHjy9fjS9Wzb0ebbQmaWCQVLBJIqgVuAC4DpwFWSpncq9jQwMyKOA34JfK1Q8eyLOQvXMKBfBadNGVnsUMzMCq6QNYJTgMUR8XJEtAB3kMxtsFNEzI2IrenqY8D4AsaTl4hgdl09p08ZxYB+HmXDzMpfIRPBOGBFzvrKdFtXrgHu3dMOSddKmidpXkNDQw+G+HqL67ewcsM2dxs1s8zoE43Fkq4mmQf55j3tj4hbI2JmRMysrS3sU76z00loPEm9mWVFISfgXQVMyFkfn27bjaTzgM8Cb46I5gLGk5c5dfUcNXYohwwfWOxQzMx6RSFrBE8CUyVNllQNXAnMyi0g6QTgu8AlEVFfwFjy0rh1B0+9ssGDzJlZphQsEUREK3AdcB+wELgzIuZLuknSJWmxm4HBwF2SnpE0q4vD9YoHX2qgrT0424nAzDKkkLeGiIh7gHs6bftCzvJ5hfz8fTVn4RpGDKrm+AnDix2KmVmv6RONxX1BW3vwwIsNnDWtlsoKP01sZtnhRJB6evkGNm7d4W6jZpY5TgSp2XX1VFWIN031JDRmli1OBKm5dfXMnHQQwwb2K3YoZma9yokAWLlhK3WvbebcI8cUOxQzs17nREBSGwDcbdTMMsmJgORp4kNH1jCldlCxQzEz63WZTwTbWtp4dMk6zj7Ck9CYWTZlPhE8umQtza3tnOtuo2aWUZlPBLPr6hlUXckpk0cUOxQzs6LIdCKICObW1XPG1FH0r/IkNGaWTZlOBAtXb2Z143Z3GzWzTMt0IphTtwaAs47008Rmll0ZTwT1HDd+GKOHDCh2KGZmRZPZRLBuSzNPr9jIOX6IzMwyLrOJ4MEXG4jAicDMMi+ziWB2XT21Q/pzzCHDih2KmVlRZTIR7Ghr56FFDZx9RC0VnoTGzDIuk4lg3rINbG5u5Rx3GzUzy2YimFO3hn6V4oypo4odiplZ0WU0EdRz6mEjGdy/qtihmJkVXeYSwbK1TSxpaHJvITOzVOYSwex0EhonAjOzROYSwa//vJJpYwZz6EhPQmNmBhlLBPWbtjP/1U1cdNwhxQ7FzKzPyFQiWLFhKwDHjfdDZGZmHTKVCObWNQAwbGC/IkdiZtZ3ZCoRbNvRBsCx41wjMDPrkKlEMP/VRmaMH0ZVZaZO28ysW5m5Ira3B/NXbeIY1wbMzHaTmUSwfP1WNje3+raQmVknBU0Eks6XtEjSYkk37GF/f0m/SPc/LmlSoWJZuHoTAEd72Gkzs90ULBFIqgRuAS4ApgNXSZreqdg1wIaIOBz4BvDVQsWzcdsOAEYNqS7UR5iZlaRC1ghOARZHxMsR0QLcAVzaqcylwI/S5V8C50oqyAQBTc2tANRUe6A5M7NchUwE44AVOesr0217LBMRrUAjMLLzgSRdK2mepHkNDQ37FczEETVccMzB1FRX7tf7zczKVUl8PY6IW4FbAWbOnBn7c4y3Hn0wbz364B6Ny8ysHBSyRrAKmJCzPj7dtscykljDehYAAAf3SURBVKqAYcC6AsZkZmadFDIRPAlMlTRZUjVwJTCrU5lZwPvT5cuAORGxX9/4zcxs/xTs1lBEtEq6DrgPqAR+EBHzJd0EzIuIWcD/AD+RtBhYT5IszMysFxW0jSAi7gHu6bTtCznL24H3FDIGMzPrXmaeLDYzsz1zIjAzyzgnAjOzjHMiMDPLOJVab01JDcAr+/n2UcDaHgynFPics8HnnA0Hcs6HRkTtnnaUXCI4EJLmRcTMYsfRm3zO2eBzzoZCnbNvDZmZZZwTgZlZxmUtEdxa7ACKwOecDT7nbCjIOWeqjcDMzF4vazUCMzPrxInAzCzjyjIRSDpf0iJJiyXdsIf9/SX9It3/uKRJvR9lz8rjnK+XtEDSc5JmSzq0GHH2pL2dc065d0sKSSXf1TCfc5Z0efpvPV/Sz3s7xp6Wx//tiZLmSno6/f99YTHi7CmSfiCpXtILXeyXpG+lv4/nJJ14wB8aEWX1IhnyeglwGFANPAtM71TmI8B30uUrgV8UO+5eOOezgZp0+W+zcM5puSHAQ8BjwMxix90L/85TgaeBg9L10cWOuxfO+Vbgb9Pl6cCyYsd9gOd8JnAi8EIX+y8E7gUEnAo8fqCfWY41glOAxRHxckS0AHcAl3Yqcynwo3T5l8C5ktSLMfa0vZ5zRMyNiK3p6mMkM8aVsnz+nQG+DHwV2N6bwRVIPuf8YeCWiNgAEBH1vRxjT8vnnAMYmi4PA17txfh6XEQ8RDI/S1cuBX4ciceA4ZLGHshnlmMiGAesyFlfmW7bY5mIaAUagZG9El1h5HPOua4h+UZRyvZ6zmmVeUJE/F9vBlZA+fw7TwOmSXpE0mOSzu+16Aojn3P+EnC1pJUk8598tHdCK5p9/Xvfq5KYvN56jqSrgZnAm4sdSyFJqgC+DnygyKH0tiqS20NnkdT6HpJ0bERsLGpUhXUVcFtE/Luk00hmPTwmItqLHVipKMcawSpgQs76+HTbHstIqiKpTq7rlegKI59zRtJ5wGeBSyKiuZdiK5S9nfMQ4BjgAUnLSO6lzirxBuN8/p1XArMiYkdELAVeJEkMpSqfc74GuBMgIv4EDCAZnK1c5fX3vi/KMRE8CUyVNFlSNUlj8KxOZWYB70+XLwPmRNoKU6L2es6STgC+S5IESv2+MezlnCOiMSJGRcSkiJhE0i5ySUTMK064PSKf/9t3k9QGkDSK5FbRy70ZZA/L55yXA+cCSDqKJBE09GqUvWsW8L6099CpQGNErD6QA5bdraGIaJV0HXAfSY+DH0TEfEk3AfMiYhbwPyTVx8UkjTJXFi/iA5fnOd8MDAbuStvFl0fEJUUL+gDlec5lJc9zvg94q6QFQBvwqYgo2dpunuf8SeB7kj5B0nD8gVL+YifpdpJkPipt9/gi0A8gIr5D0g5yIbAY2Ap88IA/s4R/X2Zm1gPK8daQmZntAycCM7OMcyIwM8s4JwIzs4xzIjAzyzgnAuuzJI2U9Ez6ek3Sqpz16h76jAfSkS2fTYdlOGI/jnGPpOHp6yM52w+R9MseiHGSpG3peS+Q9GNJ/fbynrMkvfFAP9uywYnA+qyIWBcRx0fE8cB3gG90rEdES/pUeE/4i4iYQTIQ4c37EeeF6RAOw0lGtu3Y/mpEXNZDMS5Jfw/HkjxJevleyp8FOBFYXpwIrKRIuk3SdyQ9DnxN0pck/UPO/heUzi8h6WpJT6TfpL8rqXIvh38IODx9YvPm9FjPS7oiPd5YSQ+lx3tB0pvS7cvSp3j/FZiS7r85/Sb/QlrmMUlH58T5gKSZkgYpGX/+CSXj6e9pBNWdIqINeIJ0kDFJFyuZU+NpSfdLGpOe/98An0hjeZOkWkm/kvRk+jo971+6lT0nAitF44E3RsT1XRVIhxq4Ajg9/SbdBvzFXo57MfA88C7geGAGcB5ws5Jhft8L3JcebwbwTKf330D6zT0iPtVp3y9Iv8WnxxqbDnfxWZIhTk4hmTPiZkmDujmvAcAbgN+lm/4InBoRJ5AM0fzpiFjG7jWoh4FvpusnA+8Gvr+X34VlSNkNMWGZcFf6zbg75wInAU+mQ2oMBLoaY+lnkrYBy0iGML4euD39jDWSHgROJhn35gfp/fm7I6JzIujOncDvSYYLuJxkHgyAtwKX5NRqBgATgYWd3j9F0jPAZOD/IuK5dPt44BdpcqkGlnbx+ecB07Vr2o2hkgZHxJZ9OAcrU04EVoqacpZb2b1mOyD9KeBHEXFjHsf7i9zB6NTFHEUR8ZCkM4G3A7dJ+npE/DifgCNilaR1ko4jqan8TU6c746IRXs5xJKIOD69BfWIpEvScXa+DXw9ImZJOotkbP49qSCpOZTDBD3Ww3xryErdMpJp/Tomopmcbp8NXCZpdLpvhPKfp/lh4ApJlZJqSaYOfCJ9/5qI+B7JrZXOc8VuJhn+uiu/AD4NDMv5Rn8f8FGl2UfJKLFdioi1JLegOhLcMHYNQfz+nKKdY/k9ORO2SDq+u8+xbHEisFL3K2CEpPnAdSTj7xMRC4DPAb+X9BzwByDf6fz+F3iOZH7cOST33V8j6YnzrKSnSb7VfzP3Tekon4+kDcl76n30S5KRbu/M2fZlkpEln0vP4ct5xHc3UJM2Vn+JZETZp4C1OWV+C7yzo7EY+BgwU8lk5wvYVSMx8+ijZmZZ5xqBmVnGORGYmWWcE4GZWcY5EZiZZZwTgZlZxjkRmJllnBOBmVnG/X+JOVEQOxOzEwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set areaUnderROC: 0.8946111442392121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.read.csv('predictions.csv', header = True, inferSchema = True)\n",
        "cols2 = df2.columns\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rePPdsffON8C",
        "outputId": "b067cd42-35e7-4033-a4da-b1211117b678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- trackID: integer (nullable = true)\n",
            " |-- album_score: integer (nullable = true)\n",
            " |-- artist_score: integer (nullable = true)\n",
            " |-- genre1_score: integer (nullable = true)\n",
            " |-- genre2_score: integer (nullable = true)\n",
            " |-- genre3_score: integer (nullable = true)\n",
            " |-- genre4_score: integer (nullable = true)\n",
            " |-- genre5_score: integer (nullable = true)\n",
            " |-- genre6_score: integer (nullable = true)\n",
            " |-- genre7_score: integer (nullable = true)\n",
            " |-- genre8_score: integer (nullable = true)\n",
            " |-- genre9_score: integer (nullable = true)\n",
            " |-- genre10_score: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test2=df2\n",
        "print(test2)\n",
        "\n",
        "numericCols = ['album_score', 'artist_score', 'genre1_score', 'genre2_score', 'genre3_score', 'genre4_score', 'genre5_score', 'genre6_score', 'genre7_score', 'genre8_score', 'genre9_score', 'genre10_score']\n",
        "stages = []\n",
        "assemblerInputs =  numericCols\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]\n",
        "\n",
        "pipeline = Pipeline(stages = stages)\n",
        "pipelineModel = pipeline.fit(df2)\n",
        "df2 = pipelineModel.transform(df2)\n",
        "selectedCols = ['features'] + cols2\n",
        "df2 = df2.select(selectedCols)\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJKf0xtRzVh",
        "outputId": "db7aaa61-8936-4116-ac6b-bc309cca2814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[userID: int, trackID: int, album_score: int, artist_score: int, genre1_score: int, genre2_score: int, genre3_score: int, genre4_score: int, genre5_score: int, genre6_score: int, genre7_score: int, genre8_score: int, genre9_score: int, genre10_score: int]\n",
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- trackID: integer (nullable = true)\n",
            " |-- album_score: integer (nullable = true)\n",
            " |-- artist_score: integer (nullable = true)\n",
            " |-- genre1_score: integer (nullable = true)\n",
            " |-- genre2_score: integer (nullable = true)\n",
            " |-- genre3_score: integer (nullable = true)\n",
            " |-- genre4_score: integer (nullable = true)\n",
            " |-- genre5_score: integer (nullable = true)\n",
            " |-- genre6_score: integer (nullable = true)\n",
            " |-- genre7_score: integer (nullable = true)\n",
            " |-- genre8_score: integer (nullable = true)\n",
            " |-- genre9_score: integer (nullable = true)\n",
            " |-- genre10_score: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = lrModel.transform(df2)\n",
        "predictions2.select('userID', 'trackID', 'probability', \n",
        "                   'rawPrediction', 'prediction' ).show(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg4y430DSGYL",
        "outputId": "17704bc0-49c1-4c6c-9ffc-cf82869f8e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+--------------------+--------------------+----------+\n",
            "|userID|trackID|         probability|       rawPrediction|prediction|\n",
            "+------+-------+--------------------+--------------------+----------+\n",
            "|199810| 208019|[0.26764161841138...|[-1.0066211456166...|       1.0|\n",
            "|199810|  74139|[0.18954015823996...|[-1.4530008735541...|       1.0|\n",
            "|199810|   9903|[0.16445692331696...|[-1.6254332330968...|       1.0|\n",
            "|199810| 242681|[0.16445692331696...|[-1.6254332330968...|       1.0|\n",
            "|199810|  18515|[0.64329868481930...|[0.58971035455065...|       0.0|\n",
            "|199810| 105760|[0.88131465745200...|[2.00493891077002...|       0.0|\n",
            "|199812| 276940|[0.16445692331696...|[-1.6254332330968...|       1.0|\n",
            "|199812| 142408|[0.99897292883548...|[6.88001645788596...|       0.0|\n",
            "|199812| 130023|[0.99928089687161...|[7.23678641564157...|       0.0|\n",
            "|199812|  29189|[0.26764161841138...|[-1.0066211456166...|       1.0|\n",
            "|199812| 223706|[0.89515357223420...|[2.14449860582558...|       0.0|\n",
            "|199812| 211361|[0.16445692331696...|[-1.6254332330968...|       1.0|\n",
            "+------+-------+--------------------+--------------------+----------+\n",
            "only showing top 12 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = predictions2.select('userID', 'trackID', 'probability')\n",
        "predictions2.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQkK9WNCRgN",
        "outputId": "8485df49-78f8-4c62-b567-1aef30e21cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+--------------------+\n",
            "|userID|trackID|         probability|\n",
            "+------+-------+--------------------+\n",
            "|199810| 208019|[0.26764161841138...|\n",
            "|199810|  74139|[0.18954015823996...|\n",
            "|199810|   9903|[0.16445692331696...|\n",
            "|199810| 242681|[0.16445692331696...|\n",
            "|199810|  18515|[0.64329868481930...|\n",
            "|199810| 105760|[0.88131465745200...|\n",
            "|199812| 276940|[0.16445692331696...|\n",
            "|199812| 142408|[0.99897292883548...|\n",
            "|199812| 130023|[0.99928089687161...|\n",
            "|199812|  29189|[0.26764161841138...|\n",
            "+------+-------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2.toPandas().to_csv('lr_prediction2.csv')"
      ],
      "metadata": {
        "id": "Pk6w2jTKTZla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"lr_prediction2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vTrshXkLU-It",
        "outputId": "34d13e3d-635d-4c27-891c-e4b87ca26ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5cc4cdb-d693-4b45-a00f-b112b4b8792c\", \"lr_prediction2.csv\", 7525581)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label',maxDepth = 20)\n",
        "dtModel = dt.fit(train)\n",
        "predictions3 = dtModel.transform(df2)\n",
        "predictions3 = predictions3.select('userID', 'trackID', 'probability')\n",
        "predictions3.show(10)\n",
        "predictions3.toPandas().to_csv('dt_prediction.csv')\n",
        "files.download(\"dt_prediction.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "HHmt_4TFVKPX",
        "outputId": "2935fc44-9fc2-4fd9-b69d-fd3c1d9904f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+--------------------+\n",
            "|userID|trackID|         probability|\n",
            "+------+-------+--------------------+\n",
            "|199810| 208019|[0.27329192546583...|\n",
            "|199810|  74139|[0.20370370370370...|\n",
            "|199810|   9903|[0.16123778501628...|\n",
            "|199810| 242681|[0.16123778501628...|\n",
            "|199810|  18515|[0.74242424242424...|\n",
            "|199810| 105760|[0.81756756756756...|\n",
            "|199812| 276940|[0.16123778501628...|\n",
            "|199812| 142408|[0.99725776965265...|\n",
            "|199812| 130023|[0.99725776965265...|\n",
            "|199812|  29189|[0.27329192546583...|\n",
            "+------+-------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fd835775-c504-4ebe-b051-809dc8059c07\", \"dt_prediction.csv\", 7054827)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest classifier in pySpark\n",
        "\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
        "rfModel = rf.fit(train)\n",
        "predictions4 = rfModel.transform(df2)\n",
        "predictions4 = predictions4.select('userID', 'trackID', 'probability')\n",
        "predictions4.show(10)\n",
        "predictions4.toPandas().to_csv('rf_prediction.csv')\n",
        "files.download(\"rf_prediction.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "V_bdCKzZVxDb",
        "outputId": "c774a2ba-1830-4efa-bc2e-00b2a9f013f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+--------------------+\n",
            "|userID|trackID|         probability|\n",
            "+------+-------+--------------------+\n",
            "|199810| 208019|[0.25715831260528...|\n",
            "|199810|  74139|[0.20386290270793...|\n",
            "|199810|   9903|[0.18424878796411...|\n",
            "|199810| 242681|[0.18424878796411...|\n",
            "|199810|  18515|[0.70413912504618...|\n",
            "|199810| 105760|[0.80278740089012...|\n",
            "|199812| 276940|[0.18424878796411...|\n",
            "|199812| 142408|[0.96636856019589...|\n",
            "|199812| 130023|[0.96227864779344...|\n",
            "|199812|  29189|[0.25715831260528...|\n",
            "+------+-------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85553f68-81f9-4718-8cff-6fbb8865e10b\", \"rf_prediction.csv\", 7501118)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient-Boosted Tree Classifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "gbt = GBTClassifier(maxIter=100)\n",
        "gbtModel = gbt.fit(train)\n",
        "predictions5 = gbtModel.transform(df2)\n",
        "predictions5 = predictions5.select('userID', 'trackID', 'probability')\n",
        "predictions5.show(10)\n",
        "predictions5.toPandas().to_csv('gbt_prediction.csv')\n",
        "files.download(\"gbt_prediction.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "AqFkwJh-WmWe",
        "outputId": "30a84659-045b-4b6a-e7c7-1c1a4b5c71b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+--------------------+\n",
            "|userID|trackID|         probability|\n",
            "+------+-------+--------------------+\n",
            "|199810| 208019|[0.27793794907587...|\n",
            "|199810|  74139|[0.18144406227317...|\n",
            "|199810|   9903|[0.15987347179261...|\n",
            "|199810| 242681|[0.15987347179261...|\n",
            "|199810|  18515|[0.70983007315245...|\n",
            "|199810| 105760|[0.80610523115668...|\n",
            "|199812| 276940|[0.15987347179261...|\n",
            "|199812| 142408|[0.98861966544588...|\n",
            "|199812| 130023|[0.98862026793542...|\n",
            "|199812|  29189|[0.27793794907587...|\n",
            "+------+-------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12613690-9b26-4f66-918c-47672cf96449\", \"gbt_prediction.csv\", 7503020)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgWbxDRYEn9S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}